<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Csv loader for redshift : Loads CSV file to Amazon-Redshift table from Windows CLI">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Csv loader for redshift</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/alexbuz/CSV_Loader_For_Redshift">View on GitHub</a>

          <h1 id="project_title">Csv loader for redshift</h1>
          <h2 id="project_tagline">Loads CSV file to Amazon-Redshift table from Windows CLI</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/alexbuz/CSV_Loader_For_Redshift/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/alexbuz/CSV_Loader_For_Redshift/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a id="csv-file-loader-for-amazon-redshift-db" class="anchor" href="#csv-file-loader-for-amazon-redshift-db" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CSV File Loader for Amazon Redshift DB.</h1>

<p>Loads CSV file to Amazon-Redshift table from Windows command line.</p>

<p>Features:</p>

<ul>
<li>Loads local (to your Windows desktop) CSV file to Amazon Redshift.</li>
<li>No need to preload your data to S3 prior to insert to Redshift.</li>
<li>No need for Amazon AWS CLI.</li>
<li>Works from your OS Windows desktop (command line).</li>
<li>It's executable (csv_loader_for_redshift.exe)  - no need for Python install.</li>
<li>Tt will work on any vanilla DOS for 64bit Windows.</li>
<li>AWS Access Keys are not passed as arguments. </li>
<li>Written using Python/boto/psycopg2/PyInstaller.</li>
</ul>

<h2>
<a id="version" class="anchor" href="#version" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Version</h2>

<table>
<thead>
<tr>
<th>OS</th>
<th>Platform</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td>Windows</td>
<td>32bit</td>
<td>[0.1.0 beta]</td>
</tr>
</tbody>
</table>

<h2>
<a id="purpose" class="anchor" href="#purpose" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Purpose</h2>

<ul>
<li>Ad-hoc CSV file load to Amazon Redshift table.</li>
</ul>

<h2>
<a id="how-it-works" class="anchor" href="#how-it-works" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How it works</h2>

<ul>
<li>File is staged on S3 prior to load to Redshift</li>
<li>Optional upload to Reduced Redundancy storage (not RR by default).</li>
<li>Optional "make it public" after upload (private by default)</li>
<li>S3 Key defaulted to transfer file name.</li>
<li>Load is done using COPY command</li>
<li>Target Redshift table has to exist</li>
<li>It's a Python/boto/psycopg2 script

<ul>
<li>Boto S3 docs: <a href="http://boto.cloudhackers.com/en/latest/ref/s3.html">http://boto.cloudhackers.com/en/latest/ref/s3.html</a>
</li>
<li>psycopg2 docs: <a href="http://initd.org/psycopg/docs/">http://initd.org/psycopg/docs/</a>
</li>
</ul>
</li>
<li>Executable is created using <a href="http://www.pyinstaller.org/">pyInstaller</a>
</li>
</ul>

<h2>
<a id="audience" class="anchor" href="#audience" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Audience</h2>

<p>Database/ETL developers, Data Integrators, Data Engineers, Business Analysts, AWS Developers, DevOps, </p>

<h2>
<a id="designated-environment" class="anchor" href="#designated-environment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Designated Environment</h2>

<p>Pre-Prod (UAT/QA/DEV)</p>

<h2>
<a id="usage" class="anchor" href="#usage" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Usage</h2>

<pre><code>&gt;dist-64bit\csv_loader_for_redshift.exe
#############################################################################
#CSV-to-Redshift Data Loader (v1.2, beta, 04/05/2016 15:11:53) [64bit]
#Copyright (c): 2016 Alex Buzunov, All rights reserved.
#Agreement: Use this tool at your own risk. Author is not liable for any damages
#           or losses related to the use of this software.
################################################################################
Usage:
  set AWS_ACCESS_KEY_ID=&lt;you access key&gt;
  set AWS_SECRET_ACCESS_KEY=&lt;you secret key&gt;
  set REDSHIFT_CONNECT_STRING="dbname='***' port='5439' user='***' password='***' host='mycluster.***.redshift.amazonaws.com'"
  csv_loader_for_redshift.exe &lt;file_to_transfer&gt; &lt;bucket_name&gt; [&lt;use_rr&gt;] [&lt;public&gt;]
                                                 [&lt;delim&gt;] [&lt;quote&gt;] [&lt;to_table&gt;] [&lt;gzip_source_file&gt;]

        --use_rr -- Use reduced redundancy storage (False).
        --public -- Make uploaded files public (False).
        --delim  -- CSV file delimiter (',').
        --quote  -- CSV quote ('"').
        --to_table  -- Target Amazon-Redshit table name.
        --timeformat -- timestamp format (MM/DD/YYYY HH12:MI:SS)
        --ignoreheader -- numbers of leading lines to ignore (0)
        --gzip_source_file  -- gzip input CVS file before upload to Amazon-S3 (False).

        Input filename will be used for S3 key name.

        Boto S3 docs: http://boto.cloudhackers.com/en/latest/ref/s3.html
        psycopg2 docs: http://initd.org/psycopg/docs/

"""

</code></pre>

<h1>
<a id="example" class="anchor" href="#example" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Example</h1>

<h3>
<a id="environment-variables" class="anchor" href="#environment-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Environment variables</h3>

<ul>
<li>Set the following environment variables (for all tests:</li>
</ul>

<pre><code>set AWS_ACCESS_KEY_ID=&lt;you access key&gt;
set AWS_SECRET_ACCESS_KEY=&lt;you secret key&gt;

set REDSHIFT_CONNECT_STRING="dbname='***' port='5439' user='***' password='***' host='mycluster.***.redshift.amazonaws.com'"  
</code></pre>

<h3>
<a id="csv-file-upload-into-redshift-table-test" class="anchor" href="#csv-file-upload-into-redshift-table-test" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CSV file upload into Redshift table <code>test</code>
</h3>

<pre><code>cd c:\Python35-32\PROJECTS\csv2redshift
python csv_loader_for_redshift.py Crime.csv pythonuploadtest1 ^
    -r ^
    -p ^
    -d "," ^
    -t test ^
    -z ^
    -i 1

</code></pre>

<p>Result</p>

<pre><code>S3        | Crime.csv.gz | 100%
Redshift  | test       | DONE
Time elapsed: 45.7 seconds

</code></pre>

<h4>
<a id="controlling-timestamp-format" class="anchor" href="#controlling-timestamp-format" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Controlling timestamp format</h4>

<p>Use <code>-m/--timeformat "MM/DD/YYYY HH12:MI:SS"</code> to control timestamp format.</p>

<h4>
<a id="skipping-the-header" class="anchor" href="#skipping-the-header" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Skipping the header</h4>

<p>Use <code>-i/--ignoreheader  1</code> to set number of lines to ignore in input file.</p>

<h4>
<a id="target-redshift-table-ddl" class="anchor" href="#target-redshift-table-ddl" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Target Redshift table DDL</h4>

<pre><code>drop table test;
create table test (
Incident_ID VARCHAR(20),CR_Number VARCHAR(20),Dispatch_Date_Time TIMESTAMP,Class VARCHAR(10) ,Class_Description VARCHAR(100),
Police_District_Name VARCHAR(40),Block_Address VARCHAR(100),
City VARCHAR(40),State VARCHAR(8),Zip_Code VARCHAR(10),
Agency VARCHAR(40),Place VARCHAR(40),Sector VARCHAR(10) ,Beat VARCHAR(10),PRA VARCHAR(10),Start_Date_Time TIMESTAMP,End_Date_Time TIMESTAMP,
Latitude VARCHAR(20),Longitude VARCHAR(20),Police_District_Number VARCHAR(50),Location VARCHAR(80),Address_Number VARCHAR(30));

</code></pre>

<h4>
<a id="test-data" class="anchor" href="#test-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Test data</h4>

<ul>
<li>Test data is in file <a href="https://catalog.data.gov/dataset/crime">Crime.csv</a>
</li>
</ul>

<h3>
<a id="modifying-default-script-loader" class="anchor" href="#modifying-default-script-loader" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Modifying default script loader.</h3>

<p>You can modify default Redshift COPY command this script is using.</p>

<p>Open file <a href="https://github.com/alexbuz/CSV_Loader_For_Redshift/blob/master/dist-64bit/include/loader.py">include\loader.py</a> and modify <code>sql</code> variable on line 24.</p>

<pre><code>    sql="""
COPY %s FROM '%s' 
    CREDENTIALS 'aws_access_key_id=%s;aws_secret_access_key=%s' 
    DELIMITER '%s' 
    FORMAT CSV %s 
    GZIP 
    %s 
    %s; 
    COMMIT;
    ...
</code></pre>

<h3>
<a id="download" class="anchor" href="#download" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Download</h3>

<ul>
<li><code>git clone https://github.com/alexbuz/CSV_Loader_For_Redshift</code></li>
<li>
<a href="https://github.com/alexbuz/CSV_Loader_For_Redshift/archive/master.zip">Master Release</a> -- <code>csv_loader_for_redshift 0.1.0</code>
</li>
</ul>

<h1>
<a id="faq" class="anchor" href="#faq" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>FAQ</h1>

<h4>
<a id="can-it-load-csv-file-from-windows-desktop-to-amazon-redshift" class="anchor" href="#can-it-load-csv-file-from-windows-desktop-to-amazon-redshift" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Can it load CSV file from Windows desktop to Amazon Redshift.</h4>

<p>Yes, it is the main purpose of this tool.</p>

<h4>
<a id="can-developers-integrate-csv-loader-into-their-etl-pipelines" class="anchor" href="#can-developers-integrate-csv-loader-into-their-etl-pipelines" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Can developers integrate CSV loader into their ETL pipelines?</h4>

<p>Yes. Assuming they are doing it on OS Windows.</p>

<h4>
<a id="how-fast-is-data-upload-using-csv-loader-for-redshift" class="anchor" href="#how-fast-is-data-upload-using-csv-loader-for-redshift" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How fast is data upload using <code>CSV Loader for Redshift</code>?</h4>

<p>As fast as any AWS API provided by Amazon.</p>

<h4>
<a id="how-to-inscease-upload-speed" class="anchor" href="#how-to-inscease-upload-speed" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How to inscease upload speed?</h4>

<p>Compress input file or provide <code>-z</code> or <code>--gzip_source_file</code> arg in command line and this tool will compress it for you before upload to S3.</p>

<h4>
<a id="what-are-the-other-ways-to-upload-file-to-redshift" class="anchor" href="#what-are-the-other-ways-to-upload-file-to-redshift" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>What are the other ways to upload file to Redshift?</h4>

<p>You can use 'aws s3api' and psql COPY command to do pretty much the same.</p>

<h4>
<a id="can-i-just-zip-it-using-windows-file-explorer" class="anchor" href="#can-i-just-zip-it-using-windows-file-explorer" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Can I just zip it using Windows File Explorer?</h4>

<p>No, Redshift will not recognize *.zip file format.
You have to <code>gzip</code> it. You can use 7-Zip to do that.</p>

<h4>
<a id="does-it-delete-file-from-s3-after-upload" class="anchor" href="#does-it-delete-file-from-s3-after-upload" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Does it delete file from S3 after upload?</h4>

<p>No</p>

<h4>
<a id="does-it-create-target-redshift-table" class="anchor" href="#does-it-create-target-redshift-table" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Does it create target Redshift table?</h4>

<p>No, but you can code it into default loder script  <a href="https://github.com/alexbuz/CSV_Loader_For_Redshift/blob/master/dist-64bit/include/loader.py">include\loader.py</a>.</p>

<h4>
<a id="is-there-an-option-to-compress-input-csv-file-before-upload" class="anchor" href="#is-there-an-option-to-compress-input-csv-file-before-upload" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Is there an option to compress input CSV file before upload?</h4>

<p>Yes. Use <code>-z</code> or <code>--gzip_source_file</code> argument so the tool does compression for you.</p>

<h4>
<a id="im-experiencing-errors-in-redshift-how-can-i-debug" class="anchor" href="#im-experiencing-errors-in-redshift-how-can-i-debug" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>I'm experiencing errors in Redshift. How can I debug?</h4>

<p>you can query stl_load_errors table for loader errors.</p>

<pre><code>avrocluster=# select * from stl_load_errors order by starttime desc;
</code></pre>

<p>Also, you can include print statements into <a href="https://github.com/alexbuz/CSV_Loader_For_Redshift/blob/master/dist-64bit/include/loader.py">include\loader.py</a>. script to see what command is actually executed.</p>

<h4>
<a id="explain-first-step-of-data-load" class="anchor" href="#explain-first-step-of-data-load" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Explain first step of data load?</h4>

<p>The CSV you provided is getting preloaded to Amazon-S3.
It doesn't have to be made public for load to Redshift. 
It can be compressed or uncompressed.
Your input file is getting compressed (optional) and uploaded to S3 using credentials you set in shell.</p>

<h4>
<a id="explain-second-step-of-data-load-how-data-is-loaded-to-amazon-redshift" class="anchor" href="#explain-second-step-of-data-load-how-data-is-loaded-to-amazon-redshift" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Explain second step of data load. How data is loaded to Amazon Redshift?</h4>

<p>You Redshift cluster has to be open to the world (accessible via port 5439 from internet).
It uses PostgreSQL COPY command to load file located on S3 into Redshift table.</p>

<h4>
<a id="how-do-i-skip-the-header-record-in-input-csv-file" class="anchor" href="#how-do-i-skip-the-header-record-in-input-csv-file" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How do I skip the header record in input CSV file?</h4>

<p>Use <code>-i/--ignoreheader  1</code> to set number of lines to ignore in input file.</p>

<h4>
<a id="how-do-i-set-custom-timestamp-format-for-redshift-load" class="anchor" href="#how-do-i-set-custom-timestamp-format-for-redshift-load" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>How do i set custom timestamp format for Redshift load?</h4>

<p>Use <code>-m/--timeformat "MM/DD/YYYY HH12:MI:SS"</code> to control timestamp format.</p>

<h4>
<a id="can-i-use-winzip-or-7-zip" class="anchor" href="#can-i-use-winzip-or-7-zip" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Can I use WinZip or 7-zip</h4>

<p>Yes, but you have to use 'gzip' compression type.</p>

<h4>
<a id="what-technology-was-used-to-create-this-tool" class="anchor" href="#what-technology-was-used-to-create-this-tool" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>What technology was used to create this tool</h4>

<p>I used Python, Boto, and psycopg2 to write it.
Boto is used to upload file to S3. 
psycopg2 is used to establish ODBC connection with Redshift clusted and execute <code>COPY</code> command.</p>

<h4>
<a id="im-extracting-data-from-oracle-using-sql-query-into-csv-file-how-do-i-load-it-to-redshift" class="anchor" href="#im-extracting-data-from-oracle-using-sql-query-into-csv-file-how-do-i-load-it-to-redshift" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>I'm extracting data from Oracle using SQL query into CSV file. How do I load it to Redshift.</h4>

<p>You can use <a href="https://github.com/alexbuz/Oracle-To-Redshift-Data-Loader">Oracle-to-Redshft-Data-Loader</a>.
Profide query file as input parameter and it will load data.</p>

<h4>
<a id="where-are-the-sources" class="anchor" href="#where-are-the-sources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Where are the sources?</h4>

<p>Please, contact me for sources.</p>

<h4>
<a id="can-you-modify-functionality-and-add-features" class="anchor" href="#can-you-modify-functionality-and-add-features" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Can you modify functionality and add features?</h4>

<p>Yes, please, ask me for new features.</p>

<h4>
<a id="what-other-aws-tools-youve-created" class="anchor" href="#what-other-aws-tools-youve-created" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>What other AWS tools you've created?</h4>

<ul>
<li>
<a href="https://github.com/alexbuz/Oracle_To_S3_Data_Uploader">Oracle_To_S3_Data_Uploader</a> - Stream Oracle data to Amazon- S3.</li>
<li>
<a href="https://github.com/alexbuz/S3_Sanity_Check/blob/master/README.md">S3_Sanity_Check</a> - let's you <code>ping</code> Amazon-S3 bucket to see if it's publicly readable.</li>
<li>
<a href="https://github.com/alexbuz/EC2_Metrics_Plotter/blob/master/README.md">EC2_Metrics_Plotter</a> - plots any CloudWatch EC2 instance  metric stats.</li>
<li>
<a href="https://github.com/alexbuz/S3_File_Uploader/blob/master/README.md">S3_File_Uploader</a> - uploads file from Windows to S3.</li>
</ul>

<h4>
<a id="do-you-have-any-aws-certifications" class="anchor" href="#do-you-have-any-aws-certifications" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Do you have any AWS Certifications?</h4>

<p>Yes, <a href="https://raw.githubusercontent.com/alexbuz/FAQs/master/images/AWS_Ceritied_Developer_Associate.png">AWS Certified Developer (Associate)</a></p>

<h4>
<a id="can-you-create-similarcustom-data-tool-for-our-business" class="anchor" href="#can-you-create-similarcustom-data-tool-for-our-business" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Can you create similar/custom data tool for our business?</h4>

<p>Yes, you can PM me here or email at <code>alex_buz@yahoo.com</code>.
I'll get back to you within hours.</p>

<h3>
<a id="links" class="anchor" href="#links" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Links</h3>

<ul>
<li><a href="https://github.com/alexbuz/FAQs/blob/master/README.md">Employment FAQ</a></li>
</ul>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Csv loader for redshift maintained by <a href="https://github.com/alexbuz">alexbuz</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
